#+TITLE: eduardo's website title
#+bibliography: ./refs.bib
#+HUGO_BASE_DIR: ../
#+HUGO_PAIRED_SHORTCODES: alert image
#+AUTHOR: Eduardo Bellani

* Pages
:PROPERTIES:
:EXPORT_HUGO_SECTION: /
:END:

** Home
:PROPERTIES:
:EXPORT_TITLE: homepage title
:EXPORT_FILE_NAME: _index
:EXPORT_HUGO_TYPE: homepage
:END:

# metadata for [[https://www.freecodecamp.org/news/what-is-open-graph-and-how-can-i-use-it-for-my-website/][open graph]] metadata
#+begin_description
eduardo's blog description
#+end_description

My name is Eduardo Bellani. My main interests with this page are to
write about computer science, programming, philosophy from a moderate
realist tradition, and leadership.

I have been involved in the world of technology startups for more than
15 years. As developer, manager, entrepreneur, director. Mostly with
functional programming and research oriented projects/companies.

- Disclaimer :: The opinions expressed herein are those of the author,
  and should not be construed as representing the views of any
  employers, past or present, of mine.

* Blog                                                                :@blog:
:PROPERTIES:
:EXPORT_HUGO_SECTION: blog
:END:
** How to unlock motivation for high performance in your team
:PROPERTIES:
:EXPORT_FILE_NAME: how-to-unlock-motivation-for-high-performance-in-your-team
:EXPORT_DATE: 2024-10-23
:CUSTOM_ID: how-to-unlock-motivation-for-high-performance-in-your-team
:END:

As an engineering manager(EM), one of your core tasks is to build and
maintain a team of high performance. To accomplish this, it should be
obvious that motivation is a key factor:

#+begin_quote
Why do followers join some teams but not others? How do you get
followers to exhibit enough of the critical behaviors needed for the
team to succeed? And why are some leaders capable of getting followers
to go above and beyond the call of duty? The ability to motivate others
is a fundamental leadership skill and has strong connections to building
cohesive, goal-oriented teams and getting results through others. The
importance of follower motivation is suggested in findings that most
people believe they could give as much as 15 percent or 20 percent more
effort at work than they now do with no one, including their own bosses,
recognizing any difference. Perhaps even more startling, these workers
also believed they could give 15 percent or 20 percent less effort with
no one noticing any difference. Moreover, variation in work output
varies significantly across leaders and followers. The top 15 percent of
workers in any particular job may produce 20 to 50 percent more output
than the average worker, depending on the complexity of the job. Put
another way, the best computer programmers or salesclerks might write up
to 50 percent more programs or process 50 percent more customer orders.
[cite:@curphy2018ise]
#+end_quote

Let's assume that you are convinced that having a motivated team is key
for your success as an EM. Now comes the question, how? Everyone and
their dog has advice on this, mostly about your interactions with your
followers. This article will focus on a different angle: the advice is
to you about you, or more specifically, about your vision.

Why vision? 

#+begin_quote
Followers expect leaders to provide a sense of mission and a hopeful
view of the future and to explain why they are doing what they are doing
and why it matters. [cite:@warrenfeltz2016coaching]
#+end_quote

Now, how do you develop a vision? Since action follows from essence, we
should understand what is the essence of a man. For this context, what
matters is that man is a creature in tension between his contingent
situation and the contemplation of God, the Eternal transcendence.

The way man deals with this tension sucessfully is with a story. This
story is what connects his present to the vanishing point we call the
future. [cite:@noica2009six]

Since it is likely that the vast majority of people you will encounter
as followers have no such story, they will be inclined to follow yours
as long as you present it clearly and be able to connect it to the
company's goals.

Summing it up: clarify to yourself and to others what is your story and
how it connects to the current situation. There are specific tools
available if you want help crafting your story, such as
[cite:@booker2004seven].


#+caption: Pontifical High Mass in the ruins of St Mary's Cathedral, Nagasaki, Japan. December 7th, 1949 - (5 years after the atom bomb).
[[./mass-at-nagasaki.jpg]]
#+print_bibliography:
** A simple way to deal with the principal threat to scalability
:PROPERTIES:
:EXPORT_FILE_NAME: a-simple-way-to-deal-with-the-principal-threat-to-scalability
:EXPORT_DATE: 2024-09-20
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug a-simple-way-to-deal-with-the-principal-threat-to-scalability
:CUSTOM_ID: a-simple-way-to-deal-with-the-principal-threat-to-scalability
:END:

If you have a distributed system one of the main worries you probably
have is scalability. Well, what is the principal threat to scalability
in such systems is the conflict between transactions that are used to
guarantee correct results in concurrent operations.

Such conflicts are dealt with by concurrency control, either
pessimistically via something like exclusive resource lock or
optimistically via something like serializable snapshot isolation.

Let me illustrate the threat with from the pessimistic point of view:

#+begin_quote
Access to resources guarded by an exclusive lock is serialized—only one
thread at a time may access it. Of course, we use locks for good
reasons, such as preventing data corruption, but this safety comes at a
price. Persistent contention for a lock limits scalability.

*The principal threat to scalability in concurrent applications is the
exclusive resource lock.*

Two factors influence the likelihood of contention for a lock:
1. how often that lock is requested and
2. how long it is held once acquired.
[cite:@goetz2006java]
#+end_quote

The trick that I'm going to present addresses point 1, ~how often the
lock is requested~.  Just to be clear, the same trick applies to
optimistic concurrency control (OCC):

#+begin_quote
While OCC is guaranteed to make progress, it can still perform quite
poorly under high contention. The simplest of these contention cases is
when a whole lot of clients start at the same time, and try to update
the same database row. With one client guaranteed to succeed every
round, the time to complete all the updates grows linearly with
contention. [cite:@brooker15:_expon_backof_and_jitter]
#+end_quote

So, what is the trick? A combination of a capped exponential backoff
with jittering in order to avoid synchronization of the retries of
several clients. "Oh, it can't be that simple" you say. Hear the expert
out:

#+begin_quote
After 8 years, this solution continues to serve as a pillar for how
Amazon builds remote client libraries for resilient
systems.[cite:@brooker15:_expon_backof_and_jitter]
#+end_quote

You can check the article above for an in-depth overview. If you are
curious as to what a ~real~ version looks like, below I added the code
that I contributed to Omnigres to implement this for automatic
transaction retries[cite:@bellani24:_probl].

#+begin_src c
static List *backoff_values;
static int32 retry_attempts = 0;
static int64 cap_sleep_microsecs = 10000;
static int64 base_sleep_microsecs = 1;

/**
 * The backoff should increase with each attempt.
 */
static int64 get_backoff(int64 cap, int64 base, int32 attempt) {
  int exp = Min(attempt, 30); // caps the exponent to avoid overflowing,
                              // as the user can control the # of
                              // attempts.
  return Min(cap, base * (1 << exp));
}

/**
 * Get the random jitter to avoid contention in the backoff. Uses the
 * process seed initialized in `InitProcessGlobals`.
 */
static float8 get_jitter() {
#if PG_MAJORVERSION_NUM > 14
  return pg_prng_double(&pg_global_prng_state);
#else
  return rand() / (RAND_MAX + 1.0);
#endif
}

/**
 * Implements the backoff + fitter approach
 * https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/
 */
static int64 backoff_jitter(int64 cap, int64 base, int32 attempt) {
  int64 ret = (int64)(get_jitter() * get_backoff(cap, base, attempt));
  return (ret > 0 ? ret : 1);
}

/**
 * Turns the value into something that can be consumed by
 * `pg_sleep`. The literal comes copied from there, to ensure the same
 * ratio.
 */
static float8 to_secs(int64 secs) { return (float8)secs / 1000000.0; }
#+end_src


#+caption: The Benedictine Abbey on Monte Cassino, before and after being bombed by Allied forces, February 15 1944
[[./Monte-Cassino-before-and-after-bombing-in-1944.jpg]]
#+print_bibliography:

** Debunking Event Sourcing
:PROPERTIES:
:EXPORT_FILE_NAME: debunking-event-sourcing
:EXPORT_DATE: 2024-08-23
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug debunking-event-sourcing
:CUSTOM_ID: debunking-event-sourcing
:END:

Are you looking into event sourcing? I hope this article gives you
enough information for you to properly contrast it with what I consider
an overall better alternative: temporal tables.

The context: my last article ([[#are-you-considering-event-sourcing-think-again][Are you considering Event Sourcing? Think again]]) has produced some heated responses. One of the responders
published an article ([[https://medium.com/@ZaradarTR/dear-temporal-table-developers-a3f126c010c4#e4c4][Dear Temporal Table Developers ❤]]) explaining

#+begin_quote
.. why temporal tables are ... an inferior choice, especially for
systems that require scalability, flexibility, and resilience in an
ever-changing world.
#+end_quote

Since the published reply contains an amalgamation of common positions
on this matter, I want to use it as an opportunity to create a reference
for myself and others in the future when debating this topic. Therefore,
I'll go topic by topic, linking to the appropriate place

**** Temporal Tables Aren’t True History

#+begin_quote
Events (allow) you to understand both the “what” and the “why” in a
meaningful way.
#+end_quote

Here the author is referring to the name of the event that ~should~ map
to an use-case, and claiming that this is impossible with the relational
model.

This is a bogus claim. If such data is demanded by your business rules,
there is no reason why it can't be expressed as part of a table. Here is
an example:

 #+begin_src js
   {
     "name": "reservation-bought",
     "reservation-id": 1,
     "user-id": 33,
     "seat-id": 100,
     "venue-id: 12,
   }
 #+end_src

In a SQL version, all you need is to add the intent as a desired
attribute.

 #+begin_src sql
   create table reservation (
     user_name references user (name),
     seat int,
     venue string,
     intent text,
     CHECK (intent in ('buy', 'rent'))
 #+end_src

**** Temporal Tables Impose Rigid Structure

This seems to be the main point of the article. So I'll break it down in
parts and index my replies below:

#+begin_quote
1. One of the biggest pitfalls of temporal tables is the inherent
   rigidity of the relational model.

2. As your application grows and evolves, so do your requirements, and
   changing a temporal table schema can become a significant burden.

3. Event Sourcing lets you evolve your system naturally. Each new
   feature or behavior can be introduced as a new event type, without
   the need to retroactively change the structure of your past data.
#+end_quote



1. This point seems to imply ignorance of what the relational model (RM)
   is. The RM is a logical model based on set theory and predicate
   logic. One of the major points of the RM is to allow developers the
   flexibility to choose access paths after database design.
2. Changing the schema of a temporal database can potentially be serious
   and delicate work, since it might involve changing what you claimed
   were your past beliefs. This is an universal point.
3. Given the previous point, versioning in an event sourced system can
   be at least as hard as versioning any other. As one of the leaders of
   the ES/CQRS community puts it:

   #+begin_quote
   *Over the years, I have met many developers who run into issues
   dealing with versioning, particularly in Event Sourced systems.* This
   seems odd to me. As we will discuss, Event Sourced systems are in
   fact easier to version than structural data in most instances, as
   long as you know the patterns for how to version, where they apply,
   and the trade-offs between the options.  dealing with versioning,
   particularly in Event Sourced
   systems. [cite:@young17:_version_event_sourc_system]
   #+end_quote


In fact, I'll claim that managing the evolution of a temporal structure
in event sourced systems is *harder*. I'm not alone in this
assessment:

#+begin_quote
Data conversion in event sourced systems introduces new challenges,
because of the relative novelty of the event sourcing architectural
pattern, because of the lack of standardized tools for data conversion,
and because of the large amount of data that is stored in typical event
stores.[cite:@inproceedings]
#+end_quote

**** Temporal Tables Aren’t Built for Distributed Systems

#+begin_quote
.. temporal tables simply don’t cut it. They are designed with a
single-node, relational mindset, which makes them ill-suited for
large-scale, distributed architectures.
#+end_quote

I think the author here is confusing a logical approach, temporal
tables, with an implementation in a DBMS, such as PostgreSQL or SQL
Server. One can certainly scale a modern DBMS to impressive
results[cite:@justin22:_perfor].

**** Complex Queries and Performance Overhead

#+begin_quote
With CQRS, you avoid this mess entirely. Instead of bloating your read
models with historical data, you can create dedicated read projections
that are optimized for the specific queries you need. Event-driven
architectures naturally lend themselves to this approach, allowing you
to create purpose-built views without overloading your database.
#+end_quote

The author seems to be impliying that creating projections are in any
way better than creating queries. This is the opposite of reality,
because:

1. You will pay the cost of maintaining each read
   projection[cite:@kiehl19:_dont_let_inter_dupe_you] as you would with
   a view or a snapshot
2. SQL is a DSL specifically designed for querying
3. CQRS itself adds ~risky~ complexity[cite:@fowler14:_cqrs_acces]. A
   very risky kind of complexity indeed: consistency problems.

**** A False Sense of Auditability

This is just restating [[*Temporal Tables Aren’t True History][Temporal Tables Aren’t True History]].

**** Temporal Tables Lack Flexibility

This is just restating [[*Temporal Tables Impose Rigid Structure][Temporal Tables Impose Rigid Structure]].

**** Event Streams Are the Real Temporal Model

This is just restating [[*Temporal Tables Aren’t True History][Temporal Tables Aren’t True History]].

**** Temporal Tables Create Monoliths, Not Microservices

This is confusing logical and physical concerns, or, as I put it in
  another article (see [[#how-to-avoid-frustration-with-software-architecture][How to avoid frustration with software architecture]]):

#+begin_quote
Fundamentally, I think the problem that originated the current
dissatisfaction with microservices is a double confusion:

- between the form (modules) and the matter (interacting running
  processes) of software and;
- between the the form (modules) of software and the form of software
  building organizations (teams, executing environments, deployment
  pipelines ...)
#+end_quote


*** My conclusion

The preference for Event Sourced systems seems to stem from a confusion
of physical and logical concerns and a vague desire for
~scaleability~.


#+caption: Ruins of Saint Lambert's Cathedral, Liège. Destruction started in 1795 and was caused by republican revolutionaries,
[[./Liege-ruine-stlambert.jpg]]

#+print_bibliography:



** Are you considering Event Sourcing? Think again.
:PROPERTIES:
:EXPORT_FILE_NAME:  are-you-considering-event-sourcing-think-again
:EXPORT_DATE: 2024-08-16
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug are-you-considering-event-sourcing-think-again
:CUSTOM_ID: are-you-considering-event-sourcing-think-again
:END:

Are you considering doing event sourcing? Maybe you have read that it is
necessary for your project or that you will have great benefits in doing
so.

If so, I ask you to think about an alternative. Maybe you already have
something of equal capacity in the tooling that you use and could
extract all the benefits for a fraction of the cost. What is that
something? Your old SQL RDBMS (MySQL, PostgreSQL, SQL Server, Oracle,
etc).

Here is the kicker: Temporal tables! Most SQL DBMSes already implement
such feature[cite:@jungwirth19:_survey_sql], and they basically allow
you to reap all the benefits of ES while still keeping to your CRUD
style of programming[cite:@esposito17:_soft_updat_tempor_tables]. Think
continuation passing style, but with an ~async/await~ syntax that allows
you think linearly.

To demonstrate the point, here is a table with the claimed benefits from
each approach, from the vendors themselves(slightly reworded for space
eficiency)[cite:@team24:_benef_of_event_sourc; @microsoft24:_tempor]:

| Temporal Tables                    | Event Sourcing         | Meaning                                            |
|------------------------------------+------------------------+----------------------------------------------------|
| Auditing                           | Auditing               | An immutable audit trail                           |
| Recovering from application errors | Testing & RCA          | Improving debugging by having 'what if' scenarios |
| Calculating trends                 | Analytics Capabilities | Temporal queries to see your past beliefs          |
| Reconstructing data                | Zero data loss         | All state is preserved                             |

#+caption: Mock execution of Jesus Christ by the ~Death Brigade~, communist revolutionaries led by Pascual Fresquet. Spain 1936.
[[./spanish-holocaust.jpg]]

#+print_bibliography:

** Crowdstrike's outage should not have happened, and the company is missing the point on how to avoid it in the future
:PROPERTIES:
:EXPORT_FILE_NAME: analyzing-crowdstrike-s-root-cause-analysis-or-on-missing-the-point-about-quality
:EXPORT_DATE: 2024-08-07
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug analyzing-crowdstrike-s-root-cause-analysis-or-on-missing-the-point-about-quality
:CUSTOM_ID: analyzing-crowdstrike-s-root-cause-analysis-or-on-missing-the-point-about-quality
:END:

A global IT outage occurred on [2024-07-18], with several industries
having significant economic problems (see [[#crowdstrike-appendix-1]] for
some quotes on what happened). The outage what caused by a bug in the
remote update system of the software of Crowdstrike, a popular Threat
Intelligence/Response company.

The company has published the Post Incident
Review[cite:@crowdstrike24:_crowd_prelim_post_incid_review_pir] right
after the incident and has just released its root cause analysis
[cite:@crowdstrike24:_exter_techn_root_cause_analy]. Reading them has
led me to write this article, specially the proposed mitigations.

According to the RCA, the essence of what happened was an index out of
bounds, which is a special case of a buffer overflow and considered an
*undefined behavior in C++*, the language that seems to be used to
develop crowdstrike' system[cite:@stack24:_crowd_rca_c].

Here then we get to the core of my argument: For a software of this
criticality, such problem should *not be possible*. The technology to
ensure such has existed for decades already, as can be seen in this
quote:

#+begin_quote
... we can continue to add contracts to the code until every subprogram
has a fully functional specification. By this we mean that every
subprogram has a postcondition that specifies the value of each of its
outputs and a precondition as required to constrain the input
space. Further type invariants may also be added over and above those
already present from Gold level. Once the implementation has been
completed against this full specification and all VCs generated by the
analyzer have been proved, we have reached Platinum level of SPARK
assurance.

Due to the additional effort involved in developing the specification
and proof to this level, Platinum will only be appropriate for the most
critical applications. However, it is worth considering a reduction in
unit testing for functional verification if Platinum-level proof has
been achieved, since we *know that the program will return the correct
result for all inputs, not just for those we have been able to
test*. [cite:@10.1145/3624728]
#+end_quote

Furthermore, all the technical mitigations proposed in the RCA (see the
full list of problems found and their proposals in
[[#crowdstrike-appendix-2]]) amount to just plugging holes. But safety
cannot be achieved in such way, safety needs to be designed into the
design, tools and languages used from the start of such endeavor.

If I were a client of Crowdstrike, I would be worried about the future.

*** Appendix 1: The impact
:PROPERTIES:
:CUSTOM_ID: crowdstrike-appendix-1
:END:

#+begin_quote
A major IT fault has hit services and infrastructure around the world,
with aviation, banking, healthcare and financial services among the
sectors affected.[cite:@banfield-nwachi24:_window_it]
#+end_quote

#+begin_quote
The CrowdStrike outage didn't just delay flights and make it harder to
order coffee. It also affected doctor's offices and hospitals, 911
emergency services, hotel check-in and key card systems, and work-issued
computers that were online and grabbing updates when the flawed update
was sent out. In addition to providing fixes for client PCs and virtual
machines hosted in its Azure cloud, Microsoft says it has been working
with Google Cloud Platform, Amazon Web Services, and "other cloud
providers and stakeholders" to provide fixes to Windows VMs running in
its competitors' clouds. [cite:@cunningham24:_micros]
#+end_quote

#+begin_quote
While software updates may occasionally cause disturbances, significant
incidents like the CrowdStrike event are infrequent. We currently
estimate that CrowdStrike’s update affected 8.5 million Windows devices,
or less than one percent of all Windows machines. While the percentage
was small, the broad economic and societal impacts reflect the use of
CrowdStrike by enterprises that run many critical services. [cite:@weston24:_helpin_crowd]
#+end_quote

*** Appendix 2:  What happened
:PROPERTIES:
:CUSTOM_ID: crowdstrike-appendix-2
:END:

Here is the list of problems found and their mitigations proposed by
Crowdstrike's RCA[cite:@crowdstrike24:_exter_techn_root_cause_analy]
(slightly reworded for space eficiency):

| Finding                                                            | Mitigation                                          |
|--------------------------------------------------------------------+-----------------------------------------------------|
| The number of input fields .. not validated at sensor compile time | Validate the number of input fields at compile time |
| Missing runtime array bounds check                                 | Add runtime input array bounds checks               |
| Lack of variety in testing                                         | Increase test coverage                              |
| Inconsistency between validator and interpreter                    | Fix the instance of inconsistency and add checks    |
| No validation in the interpreter                                   | Add tests                                           |
| No staged deployment                                               | Add staged deployment                               |

#+caption: St Nedelya Church, partially destroyed in a terrorist attack by the Bulgarian Communist Party. 16 April 1925.
[[./St Nedelya.jpg]]

#+print_bibliography:
** How to avoid frustration with software architecture
:PROPERTIES:
:EXPORT_FILE_NAME: how-to-avoid-frustration-with-software-architecture
:EXPORT_DATE: 2024-07-18
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug how-to-avoid-frustration-with-software-architecture
:CUSTOM_ID: how-to-avoid-frustration-with-software-architecture
:END:

It is becoming more common for companies to come out with stories on the
downsides of distributed microservice
architectures[fn:9][cite:@kolny23:_scalin_prime_video;
@10.1145/3593856.3595909].

Instead of hopping in this bandwagon, as tempting as this might be, I
want to suggest how could one avoid being caught in such situation in
the first place.

Fundamentally, I think the problem that originated the current
dissatisfaction with microservices is a double confusion:

- between the form (modules) and the matter (interacting running
  processes) of software and[cite:@sep-form-matter];
- between the the form (modules) of software and the form of software
  building organizations (teams, executing environments,
  deployment pipelines ...).

Interestingly enough, such structures are the 3 categories of software
architecture proposed in a standard Software Architecture
book:

#+begin_quote
- Module structures :: partition systems into implementation units

- Component-and-connector (C&C) structures :: focus on the way the
  elements interact with each other at runtime to carry out the system’s
  functions.

- Allocation structures :: establish the mapping from software
  structures to the system’s non-software structures, such as its
  organization, or its development, test, and execution
  environments. [cite:@bass2021software]
#+end_quote

*** So what?

In order to avoid confusion and unecessary costs, the next time you are
discussing software architecture:

1. Make sure you know which category you are talking about;
2. Insist on exaustive definitions of key terms (such as ~module~);
3. Be sure to refer to reputable sources.

#+caption: Print of the destruction in the Church of Our Lady in Antwerp, the "signature event" of the Beeldenstorm, 20 August 1566, by Frans Hogenberg
[[./Beeldenstorm_(Iconoclastic_Fury)_in_Antwerpen_1566_Frans_Hogenberg.jpg]]

#+print_bibliography:


** How to avoid a common career pitfall
:PROPERTIES:
:EXPORT_FILE_NAME: how-to-avoid-a-common-career-pitfall
:EXPORT_DATE: 2024-07-02
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug how-to-avoid-a-common-career-pitfall
:CUSTOM_ID: how-to-avoid-a-common-career-pitfall
:END:

If the way you think others see you is in stark contrast to how others
actually see you, you are in danger of derailing in your career.

To avoid that, here are 3 steps, and a reference:

   1) Ask and *embrace* feedback from bosses, peers and followers[fn:1],
   2) Expose your most cherished ideas to the most intense forms of public scrutiny you can find,
   3) See ways to measure yourself, such as 360 feedback mechanisms and
      validated personality assessments.

It all boils down to reducing your own cognitive
dissonance[cite:@festinger1957theory], which is:

#+begin_quote
... The maximum dissonance which could exist ...  determined by the
resistance to admitting that he had been wrong or foolish.
#+end_quote

#+caption: Abbey of St Victor, before being destroyed by republican revolutionaries during the French Revolution
[[./French_School_-_View_of_the_abbey_of_Saint-Victor_(Saint_Victor)_former_abbey_of_regular_canons_-_(MeisterDrucke-917697).jpg]]

#+print_bibliography:


** Integrity Constraints and business value
:PROPERTIES:
:EXPORT_FILE_NAME: constraints-and-business-value
:EXPORT_DATE: 2024-06-26
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug constraints-and-business-value
:CUSTOM_ID: constraints-and-business-value
:END:

Again with this database business? Let me try to motivate you dear
reader before I start again with a illustrative case: SQL Injections!

- SQL injection is one of the oldest vulnerabilities still present in
  the OWASP TOP 10 [cite:@sql_injection]
- A well documented case puts the cost of one SQL Injection in USD 196k
  [cite:@group14:_global_threat_intel_repor]


Ok, and how these are related to databases, and more specifically
constraints? And what are these constraints?

#+begin_quote
*Constraints* are informal business rules (BR) expressed in natural
language that constrain the values of the shared properties of entity
members of a class.

*Integrity constraints* are the formalized versions of the constraints
as first order predicates that represent them in the database, expressed
in a specific data language and enforced by the DBMS in the database for
all applications, with potential reduction in application development
and maintenance estimated at as high as 80%.

Integrity independence (II)—DBMS-enforced integrity in the database—was
a major objective and is an advantage of database management in general
and relational database management in particular (and is enshrined as
one of the famous 12 Codd rules). It is much superior to
application-enforced integrity— *a redundant, unreliable and prone to
error development and maintenance burden— which was readily subvertible*. [cite:@pascal_guide]
#+end_quote

Ok, say I got your attention about SQL Injections and you have some
clarity on what I mean by constraints. How do I connect these 2 topics?

Here is how: if developers were aware that you could encode your
authentication/authorization rules at the DBMS level as integrity
constraints, SQL injections would be impossible!

#+begin_quote
... why do it?

*Security:*
- All access control performed by database – even if application code is compromised
- Essentially, users can be given freeform sql access – database is a
  Fort Knox and will not allow unauthorized operations

*Developer productivity:*
- No more time spent on access control and worrying about security
- Even the new guy can now safely work on applications, api’s etc.
- Worst case, api breaks, but the data is perfectly safe [cite:@swart19:_row_level_secur]
#+end_quote

Consider the double effect of properly encoding this integrity
constraint (data access) where it belongs (with the system managing the data):

1. You avoid an entire class of common and expensive problems
2. Because of that, your developers can work on your actual product
   instead of solving this non issue over and over again.

#+caption: Santa Maria del Mar destroyed by communist arson, circa 1936
[[./st-maria-civil-war.jpg]]


#+print_bibliography:

** Substantial and accidental forms of a SQL expression
:PROPERTIES:
:EXPORT_FILE_NAME: substantial-and-accidental-forms-of-a-sql-expression
:EXPORT_DATE: 2024-06-20
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug substantial-and-accidental-forms-of-a-sql-expression
:CUSTOM_ID: substantial-and-accidental-forms-of-a-sql-expression
:END:

#+begin_verse
Multiplicity of parts, variety, and unity of plan which
combines the parts into a coherent whole, --
such are the elements of order found in all beauty.
[cite:@de2023system]
#+end_verse

I have been working with data intensive applications for a while and of
course that means exposure to a lot of SQL, both personally and training
other developers.

In these experiences I have noticed that it is sometimes harder than it
should be to grasp what SQL is doing, specially since its accidental
form makes understanding its substantial form so hard. In this post I'm
going to try to help the reader separate the two and understand SQL
better.

But first, some definitions of terms:

#+begin_quote
... *form* is the principle of organization of a thing’s matter, or the
thing’s intelligible nature, form can be of two kinds.

... (it) can be *substantial*, organizing the matter into the
kind of thing that the substance is.

On the other hand, form can be *accidental*, organising some part of an
already constituted substance.

- *substantial form* always ... brings a new substance into existence;

- accidental form simply informs an already existing substance, and in
  doing so it simply modifies some substance. [cite:@acquinas_metaphysics_iep]
#+end_quote

One of the core problems with SQL and in particular its ~SELECT~
expression is that the way it is written/read (and the usual
expectations of the terms such as ~SELECT/FROM~ ...) is very different
from what is actually taking place.

Let's discuss this fact starting from an example (the example and much
of the discussion are taken from [cite:@10.5555/249527])

#+begin_src sql
  SELECT
    P.PNO,
    'Weight in grams =' AS TEXT1,
    P.WEIGHT * 454 AS GMWT,
    P.COLOR,
    'Max Quantity =' AS TEXT2,
    MAX(SQ.QTY) AS MQTY
  FROM P, SP
  WHERE
    P.PNO = SP.PNO
    AND (P.COLOR = 'Red' OR P.COLOR = 'Blue')
    AND SP.QTY > 200
  GROUP BY
    P.PNO,
    P.WEIGHT,
    P.COLOR
  HAVING SUM(SP.QTY) > 350
#+end_src

The difficulty here starts right at the begging, since the ~SELECT~
clause is the first to be read and written, but it is the *last* to be
evaluated. Here is how to interpret this ~SELECT~ expression:

1. *FROM* <<join>>: The source of the data. An usually overseen point is
   that the ~FROM~ clause is actually a ~JOIN~ (a ~CROSS JOIN~
   specifically).
2. *WHERE* <<restriction>>: The result of the ~JOIN~ of the
   [[join][previous step]] is reduced by elimination of rows (a process
   called ~RESTRICTION~ in the Relational Algebra).
3. *GROUP BY* <<dictionary>>: This is one of the most complex parts of
   the expression because it goes outside the Relational Algebra. You
   can think of it as creating, from the [[restriction][restricted table]], a Dictionary
   where the keys are a combination of the values of the defined columns
   and the referenced values are all the rows where the keys exist.

   *NOTE HOWEVER* that such Dictionary is *NOT* a proper table. And that is why a
   ~GROUP BY~ clause will always demand a corresponding ~SELECT~ clause
   that turns such Dictionary into a proper table.
4. *HAVING* <<filter>>: This clause applies to the [[dictionary][Dictionary values
   generated by GROUP BY]], filtering all rows that do not match the
   condition. This is another operator that sits outside the Relational
   Algebra.
5. *SELECT* : This is called a ~PROJECTION~ in Relational Algebra. It is
   where you pick the colums of the table. It is also where each group
   resulting from the [[filter][HAVING filter]] should now generate a single result
   row, by this process:
   1. The part number, weight, color and maximum quantity are extracted from the Dictionary
   2. The weight is converted to grams
   3. Two literals are added ('Weight in grams =', 'Max Quantity =').
   4. All these insertions are ordered. The result looks like this:


| PNO | TEXT1             | GMWT | COLOR | TEXT2          | MQTY |
|-----+-------------------+------+-------+----------------+------|
| P1  | Weight in grams = | 5448 | Red   | Max Quantity = |  300 |
| P5  | Weight in grams = | 5448 | Blue  | Max Quantity = |  400 |


*** So what

I hope the reader will leave with a better appreciation of what a SQL
~SELECT~ expression actually is, instead of what it looks like. I also
think that understanding the concept of substantial vs accidental form
can help the reader a lot in understanding things like such expression
in the future.

I also think a point that deserves attention is how worse the ~SELECT~
expression becomes by SQL's introduction of operators that don't fit the
relational algebra (~GROUP BY~ and ~HAVING~ clauses). Besides such, the
~SELECT~ expression is merely a ~JOIN->RESTRICT->PROJECT~ sequence.

#+caption: Santa Maria del Mar destroyed by communist arson, circa 1936
[[./st-maria-civil-war--comparision-2.jpg]]

#+print_bibliography:

** Why updateable views, or, Why modules matter?
:PROPERTIES:
:EXPORT_FILE_NAME: why-updateable-views-or-why-modules-matter
:EXPORT_DATE: 2024-06-06
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug why-updateable-views-or-why-modules-matter
:CUSTOM_ID: why-updateable-views-or-why-modules-matter
:END:

[[https://www.linkedin.com/feed/update/urn:li:activity:7203831867937091584?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7203831867937091584%2C7203924209067008000%29&replyUrn=urn%3Ali%3Acomment%3A%28activity%3A7203831867937091584%2C7204472979404005376%29&dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287203924209067008000%2Curn%3Ali%3Aactivity%3A7203831867937091584%29&dashReplyUrn=urn%3Ali%3Afsd_comment%3A%287204472979404005376%2Curn%3Ali%3Aactivity%3A7203831867937091584%29][Continuing]] a rich conversation that sparked [[#a-real-life-example-of-database-design][other]] [[#relational-model-design][posts]], I was asked to
justify updateable views which, to me, are analogous to module'
signatures (a topic for another post). Here's the full exchange.

 #+begin_quote
 1) Why is the logical model more likely to be correct and immutable from
    the perspective of the app than the physical one?
 #+end_quote

This question seems to mistake logical and physical independence.

- Logical independence ::  the ability to change the form without
  affecting clients.

- Physical independence :: the ability to change the implementation
  without changing the form.


#+begin_quote
2) In an updateable view world, how would you explain deadlocks
   occurring to the developers consuming the model (since they can no
   longer "see" the physical tables that implement it)

3) Similarly, how will you explain the performance characteristics of
   that model when someone updates the updatable view (example: updating
   a column that is a primary key is MUCH cheaper then one that is a
   foreign key - yet they look the same in the logical representation
   shows to the developer)

4) In the same line of reasoning: How do you explain to developers why
   there is a vastly different performance characteristics selecting
   data from the same view even though queries look almost identical?
#+end_quote

All these seem to boil down to: how do you explain performance and
concurrency issues to the clients of the view? I'll make an analogy with
RPC endpoints, which are the most widely used alternative to updateable
views. Such endpoints use documentation to explain their capabilities
limitations to their clients.

 #+begin_quote
 5) Which skill is more common and cheapest to acquire: A database
    developer who can create such a logical model or the developer who
    can modify apps in case we got something about the model wrong?
 #+end_quote

The logical model will be created, and SQL is a better language for
that, since it at least can be declarative. In that sense, I think SQL
is cheaper because it provides a better language than the ones mostly
used. But the real advantages are:

1. Avoidable rework. The logical contract is done once. In RPC
   alternatives such contract can be implemented in multiple apps.
2. Consistency. Having the DBMS be the source of truth instead of
   multiple DBMS instances avoids consistency problems, which are widely
   considered the most expensive problems in the industry.

#+caption: Santa Maria del Mar destroyed by communist arson, circa 1936
[[./st-maria-civil-war--comparision.jpg]]


** A real life example of database design
:PROPERTIES:
:EXPORT_FILE_NAME: a-real-life-example-of-database-design
:EXPORT_DATE: 2024-05-27
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug a-real-life-example-of-database-design
:CUSTOM_ID: a-real-life-example-of-database-design
:END:

In a followup to [[#relational-model-design][How to use the relational model to do database design?]],
I was asked to provide an example to illustrate the point:


#+begin_quote
Can you walk through a real life example of modelling, let's say, a car
(it's always a car isn't it?).. Consider that the car may have 2WD, 4WD
and also let say we allow truck types of cars with 6 wheels. Cars have
various engine types and depending on the model of car, some colours are
available and some are not. How would you apply the logical design to
this idea and where would such a design lead you if you were to
implement it into the physical world?
#+end_quote

Here is a list of predicates that provide such an example:

1. There exists car of models ~$MOD~
2. Cars can have transmission ~$TRA~
3. Cars can have engines ~$ENG~
4. Cars can have colors ~$COL~
5. Model ~$MOD~ can have color ~$COL~
6. Model ~$MOD~ can have engine ~$ENG~
7. Model ~$MOD~ can have transmission ~$TRA~

#+caption: Spanish cathedral destroyed by communist arson, circa 1937
[[./burning-cathedral-spanish-civil-war.jpg]]


** How to use the relational model to do database design?
:PROPERTIES:
:EXPORT_FILE_NAME: how-to-use-the-relational-model-to-do-database-design
:EXPORT_DATE: 2024-05-26
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug how-to-use-the-relational-model-to-do-database-design
:CUSTOM_ID: relational-model-design
:END:

On a recent [[https://www.linkedin.com/feed/update/urn:li:activity:7199813569549328386?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7199813569549328386%2C7199820740962004992%29&replyUrn=urn%3Ali%3Acomment%3A%28activity%3A7199813569549328386%2C7200430915628462080%29&dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287199820740962004992%2Curn%3Ali%3Aactivity%3A7199813569549328386%29&dashReplyUrn=urn%3Ali%3Afsd_comment%3A%287200430915628462080%2Curn%3Ali%3Aactivity%3A7199813569549328386%29 ][exchange]] I was asked the following:

#+begin_quote
... what you mean that you use the relation model to design? ...
#+end_quote

Let's first start with the motivation: *Why* should one use the
relational model(RM) to do database design? Here is my one line answer:

/It makes it possible to have and to maintain the integrity of your
business rules./

To illustrate this point, here are some examples of problems that one
faces when one does not have such integrity:

- A status got written to 'Done', but the data that was expected to be
  there was not (eventual consistency)
- Some data that your application depends on got deleted (delete anomaly)
- A join returns more information than expected (update anomaly)
- Slow queries (optimizer problems due to duplicates)
  - Ambiguous duplicates in results (duplicates)
- Wrong query results (NULLs)


Now to the point at hand: How would one use the relational model to
design a database? Let me start by a definition of what is the
relational model:

#+begin_quote
1) An open-ended collection of scalar types, including type BOOLEAN in
   particular
2) A type generator and an intended interpretation for relations of
   types generated thereby
3) Facilities for defining variables of such generated
   relation types
4) A assignment operator for assigning values to such variables
5) A complete (but otherwise open-ended) collection of generic operators
   for deriving values from other values
[cite:@Date_Chris2015-12-15]
#+end_quote

Let's define a database:

/A database is a set of predicates and instatiations of such as
propositions./ The RM uses relation types to represent predicates. SQL
uses table definitions. The RM uses relations to represent the arguments
of a predicate, SQL uses rows.


In short, the RM set global constraints on any database design. Here is
a (probably incomplete) list with ways that the RM drives database
design:

- Never allow NULL anywhere (avoid ~NULL~ generating operators, such as ~OUTER JOIN~)
- Never allow duplicates (avoid duplicates generating queries, such as ~<SELECT | UNION> All~)
- Never depend on position of columns or rows
- Always make sure each table represents one and only one predicate, thus being in 5NF
- Use updateable views to have logical independence (simulate them with triggers)

#+caption: Communist firing squad aiming at the Monument of the Sacred Heart on the Cerro de los Angeles, Spain. 31 August 1936
[[./SpanishLeftistsShootStatueOfChrist.jpg]]


#+print_bibliography:

** How to (not) lock yourself into architectural drawbacks, or, Microservice architecture as the reification of Pi-Calculus
:PROPERTIES:
:EXPORT_FILE_NAME: microservices-as-reification
:EXPORT_DATE: 2024-05-04
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug microservices-as-reification
:END:

#+begin_quote
/Reification/: the treatment of something abstract as a material or
concrete thing, as in the following lines from Matthew Arnold’s poem
“Dover Beach”: [cite:@refification_britannica]

#+begin_verse
/The Sea of Faith
Was once, too, at the full, and round earth’s shore
Lay like the folds of a bright girdle furled./
#+end_verse
#+end_quote

The microservice architecture(MA) has taken a deep hold in the
collective imagination of the software engineering community since at
least 2014[fn:2]. This has happened despite serious and well documented
[[#drawbacks][drawbacks]].

Such combination calls for an explanation. A sketch of such explanation
is my intent here, starting with what MA is, at bottom. At a later date
I intend to provide a history of how it came to be a dominant
architecture on our industry.

My position is that MA is a reification[cite:@refification_britannica]
of abstract processes as defined by the Pi-Calculus (PC). Why do I think
of that? Let's start by defining things.

*** Definitions

PC is a model of message-based concurrent computation and its essential
features are[cite:@Pierce1995]:

#+begin_quote
- focusing on interaction via communication rather than shared
  variables,
- describing concurrent systems using a small set of primitive operators
  and
- on deriving useful algebraic laws for manipulating expressions written
  using these operators.
#+end_quote

More concretely:

#+begin_quote
...
\\
π-calculus lets you represent processes, parallel composition of
processes, synchronous communication between processes through channels,
creation of fresh channels, replication of processes, and nondeterminism
\\
...
\\
A *process* is an abstraction of an independent thread of control. A
*channel* is an abstraction of the communication link between two
processes. Processes interact with each other by sending and receiving
*messages* over channels.
[cite:@Wing2002FAQO]
#+end_quote

Here is the best definition of the MA that I know of:

#+begin_quote
The microservice architecture pattern structures the system as a
collection of independently deployable services that communicate only
via messages through service interfaces. [cite:@bass2021software]
#+end_quote

*** How are they mapped?

So here is PC is mapped to MA:

1. *Processes* are Services(binaries loaded into memory),
2. *Channels* are either queues or some form of APIs (RPC or REST),
3. *Messages* are network calls,
4. The avoidance of *shared variables* as an avoidance of a shared DBMS.

*** Conclusion
The reader might well ask, so what? Isn't that a good thing? Well, no,
it's a very bad thing. Why?

Because once you mistake a formal entity such as the PC with a material
one such as the MA, you lock yourself out of possibilities and in
specific [[#drawbacks][drawbacks]] that might not exist in other ways to implement the
PC.

Let me illustrate the point here with a metaphor:

Say you think the formal entity called ~Boat~ can only be implemented by
~Yacht~. You now are locked into the design choices of that concrete
instantiation of the ~Boat~ form. ~Transatlantic~ or ~Canoe~ are not
possible for you.

Coming back to the case at hand, here are some examples of how you could
implement the pi-calculus without MA:

- Use a language/runtime that supports it, such as Erlang/ERT, SML/NJ or F#/.net.
- Use a framework such as Akka.
- Use a DBMS where several applications share the same DBMS but you use
  permissions and views to manage access and have logical independence.

*** Appendix: The Drawbacks
:PROPERTIES:
:CUSTOM_ID: drawbacks
:END:
#+begin_quote
- It hurts performance. The overhead of serializing data and sending it
  across the network is increasingly becoming a bottleneck. When
  developers over-split their applications, these overheads compound.
- It hurts correctness. It is extremely challenging to reason about the
  interactions between every deployed version of every microservice. In
  a case study of over 100 catastrophic failures of eight widely used
  systems, two-thirds of failures were caused by the interactions
  between multiple versions of a system.
- It is hard to manage. Rather than having a single binary to build,
  test, and deploy, developers have to manage 𝑛 different binaries, each
  on their own release schedule. Running end-to-end tests with a local
  instance of the application becomes an engineering feat.
- It freezes APIs. Once a microservice establishes an API, it becomes
  hard to change without breaking the other services that consume the
  API. Legacy APIs linger around, and new APIs are patched on top.[fn:3]
- It slows down application development. When making changes that affect
  multiple microservices, developers cannot implement and deploy the
  changes atomically. They have to carefully plan how to introduce the
  change across 𝑛 microservices with their own release schedules.
[cite:@10.1145/3593856.3595909]
#+end_quote

#+caption: Cathedral of Phnom Penhl, destroyed shortly after by the Khmer Rouge. The Ministry of Posts and Telecommunications now stands on the site of the former cathedral
#+attr_html: :width 30%
[[./Cathédrale_St_Joseph_de_Phnom_Penh.jpg]]


#+print_bibliography:


** A practical principle on politics (office or otherwise)
:PROPERTIES:
:EXPORT_FILE_NAME: a-practical-principle-on-politics--office-or-otherwise
:EXPORT_DATE: 2024-04-28
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug a-practical-principle-on-politics--office-or-otherwise
:END:

If you are involved in politics, as a voter or just as an office worker
in an unfortunate situation, you would do well to remember this dictum:

#+begin_quote
When a public figure tells you something that you want to hear, question
his sincerity. When a public figure tells you something you don’t want
to hear, believe him.[cite:@what_is_truth]
#+end_quote

#+caption: The destruction of the original Church of Christ the Saviour in Moscow, Russia
[[./Christ_saviour_explosion.jpg]]

#+print_bibliography:

** A point about FAANG points
:PROPERTIES:
:EXPORT_FILE_NAME:  a-point-about-faang
:EXPORT_DATE: 2024-04-14
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug a-point-about-faang
:END:

As a technologist I often hear variations of the following phrase in my
industry:

#+begin_quote
Do it because some FAANG[cite:@faang] company did it.
#+end_quote

The structure of this argument is usually like this:

1. Technique or process X is great/bad,
2. Company C does it like this,
3. C is financially successful and famous,
4. Therefore, you should do the same X as C does.


This is a mixture of the fallacies of selection bias, appeal to
authority and false cause. Here are their definitions and some
context-sensitive examples[fn:4]:

*** Selection bias

This is a bias introduced by sampling in a way that is not
representative of the population in question.

#+begin_example
We should only look at what FAANG companies do (and ignore the ones that
did the same and went bankrupt).
#+end_example

*** Appeal to authority

You appeal to authority if you back up your reasoning by saying that it
is supported by what some authority says on the subject.

However, appealing to authority as a reason to believe something is
fallacious whenever the authority appealed to is not really an authority
in this particular subject, when the authority cannot be trusted to tell
the truth, when authorities disagree on this subject (except for the
occasional lone wolf), when the reasoner misquotes the authority, and so
forth.

#+begin_example
We should start using managed services because AWS tells us to do so.
#+end_example

*** False cause

Improperly concluding that one thing is a cause of another. Its four
principal kinds are the Post Hoc Fallacy, the Fallacy of Cum Hoc, Ergo
Propter Hoc, the Regression Fallacy, and the Fallacy of Reversing
Causation.

**** Post hoc

Suppose we notice that an event of kind A is followed in time by an
event of kind B, and then hastily leap to the conclusion that A caused
B. If so, our reasoning contains the Post Hoc Fallacy

#+begin_example
After Facebook build their system with PHP, they became hugely successful.
#+end_example

**** Cum hoc

Latin for “with this, therefore because of this.” This is a False Cause
Fallacy that doesn’t depend on time order (as does the [[*Post hoc][Post hoc]]
fallacy), but on any other chance correlation of the supposed cause
being in the presence of the supposed effect.


#+begin_example
Google uses lots of microservices and Kubernetes.
#+end_example

**** Reversing causation

Drawing an improper conclusion about causation due to a causal
assumption that reverses cause and effect.

#+begin_example
Microsoft and Google both are huge companies and have R&D centers. We
need to have a R&D center to become a huge company
#+end_example

*** Conclusion

Do pay attention to successful companies, but only when it is valid to
do so. Having a great business model and timing can allow a company to
survive very bad mistakes (such as Google firing all their project
managers once[cite:@google_firing]).

#+caption: Reims Cathedral hit during a German shell barrage, 19 September 1914.
[[./Reims Cathedral hit during a German shell barrage.jpg]]

#+print_bibliography:


** What is really the matter with the 'database'?
:PROPERTIES:
:EXPORT_FILE_NAME:  what-is-really-the-matter-with-the-database
:EXPORT_DATE: 2024-04-08
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug what-is-really-the-matter-with-the-database
:END:

How can we talk straight about a concept when the term that should
signify it is equivocated all the time?

I think this is a big part of the problem on discussions about
~databases~. Here are some ways that the term ~database~ is widely used
in the tech industry:

- A server :: ~I'll access the database in prod.~
- An instance of a  DBMS :: ~We are running PG 9.3 locally.~
- A design :: ~My database will have a user table and a product table.~
- A DBMS :: ~Let's use MongoDB as a database!~
- A storage strategy :: ~I'll store these as protobufs in my database, it will be faster!~
- A group of propositions :: (ok, almost no one uses it like this, but
  it is what ~database~ *should* mean).


Here is a more authoritative source saying the same thing:

#+begin_quote
you should be aware that people often use the term database when they
really mean DBMS (in either of the foregoing senses). Here is a typical
example: “Vendor X's database outperformed vendor T s database by a
factor of two to one.” This usage is sloppy, and deprecated, but very,
very common. (The problem is: If we call the DBMS the database, what do
we call the database? Caveat lector!)
[cite:@10.5555/861613]
#+end_quote

How can we solve this problem if we don't start by correcting ourselves?

#+caption: Cologne Cathedral stands intact amidst the destruction caused by Allied air raids, 9 March 1945
[[./800px-Cologne_Cathedral_stands_intact_amidst_the_destruction_caused_by_Allied_air_raids,_9_March_1945._CL2169.jpg]]

#+print_bibliography:

** The three traditional laws of being
:PROPERTIES:
:EXPORT_FILE_NAME:  the-three-traditional-laws-of-being
:EXPORT_DATE: 2024-03-24
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug the-three-traditional-laws-of-being
:END:

- The law of identity :: 'Whatever is, is.'
- The law of non-contradiction :: 'Nothing can both be and not be.'
- The law of excluded middle :: 'Everything must either be or not be.' [cite:@russell12]


#+caption: The North Rose window of Chartres Cathedral, France, 1190-1220 CE. The stained glass window shows scenes of Jesus Christ, the prophets and 12 kings of Judah.
#+attr_html: :width 50%
[[./chartres-rose-window.jpg]]


#+print_bibliography:


** Who should rule
:PROPERTIES:
:EXPORT_FILE_NAME: who-should-rule
:EXPORT_DATE: 2024-03-21
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug who-should-rule
:END:

If you want to become a (better) leader, you should master the four
essential characteristics for leaders: integrity, judgment, competence,
and vision[cite:@doi:10.1037/1089-2680.9.2.169]:


1. *Integrity*. A leader must be trusted to be followed.
2. *Decisiveness*. Making reasonable decisions in a timely manner.
3. *Competence*. Both your followers and your stakeholders must know
   that you not only mean well but that you can deliver.
4. *Vision*. Setting goals under the right strategy is vital for team
   and company success against its competition.

#+caption: The nave of the Saint-Sulpice Church in Paris
#+attr_html: :width 80%
[[./Saint-Sulpice-Nave-Paris.jpg]]


#+print_bibliography:

** Principles of reliable applications
:PROPERTIES:
:EXPORT_FILE_NAME: principles-of-reliable-applications
:EXPORT_DATE: 2024-03-19
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug principles-of-reliable-applications
:END:

The following are adapted from[cite:@Perry_Michael_L_2020-07-15], using
a more database centric approach:


| Principle             | Implementation                                     |
|-----------------------+----------------------------------------------------|
| Idempotence           | Client side ids; Session ids                       |
| Immutability          | Insert only DBMSes (system time in SQL 2016)       |
| Location independence | Natural keys                                       |
| Versioning            | Additive structures; Temporal dimension on schemas |


#+caption: Gargoyles of Notre-Dame de Paris
#+attr_html: :width 50%
[[./notre-dame-gargoyle.jpg]]

#+print_bibliography:

** Pots, kettles and databases
:PROPERTIES:
:EXPORT_FILE_NAME: pots-kettles-and-databases
:EXPORT_DATE: 2024-03-17
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug pots-kettles-and-databases
:END:

Sometimes you stumble upon small insights that illuminate a good chunk
of things. Recently I think I have stumbled upon what I believe is a
case of that, on the Hibernate manual[cite:@king24:_introd_hiber], of
all places. The author of the manual itself makes it clear that it is a
special section of the manual:

#+begin_quote
In this section, we’re going to give you our opinion. If you’re only
interested in facts, or if you prefer not to read things that might
undermine the opinion you currently hold, please feel free to skip
straight to the next chapter.
#+end_quote

The section can be summarized in the following recommendation and
image[cite:@king24:_introd_hiber]:

#+begin_quote
we’re not sure you need a separate persistence layer at all
#+end_quote

#+caption: Hibernate's manual suggested architecture
[[./hibernate-architecture.png]]


What I found very interesting is that the core of the author's point is
that it was misguided to believe the following:

#+begin_quote
Eventually, some folks came to believe that their DAOs shielded their
program from depending in a hard way on ORM, allowing them to "swap out"
Hibernate, and replace it with JDBC, or with something else. In fact,
this was never really true—there’s quite a deep difference between the
programming model of JDBC, where every interaction with the database is
explicit and synchronous, and the programming model of stateful sessions
in Hibernate, where updates are implicit, and SQL statements are
executed asynchronously.
#+end_quote

But the same argument applies to Hibernate itself! Why call a
transaction/Hibernate layer at all? Why not just call directly the DBMS?
So that you can *swap DBMSes?*

The following is an image that I think summarizes this article:

#+caption: Charles H. Bennett's coloured engraving from Shadow and Substance (1860), a series based on popular sayings. In this case, a coal-man and chimney sweep stop to argue in the street in illustration of "The pot calling the kettle black". A street light throws the shadow of the kitchen implements on the wall behind them.
[[./Charles_Henry_Bennett_-_The_Pot_Calling_The_Kettle_Black_(coloured_engraving)_-_(MeisterDrucke-969630).jpg]]

#+print_bibliography:
** What is database normalization and why should you do it?
:PROPERTIES:
:EXPORT_FILE_NAME: what-is-database-normalization-and-why-should-you-do-it
:EXPORT_DATE: 2024-02-25
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug what-is-database-normalization-and-why-should-you-do-it
:END:

A fully normalized database means one thing, and *only* one thing: your
relations corresponds only one predicate *under a given interpretation
(i.e. your business rules)*.

You should properly normalize your database because it:

#+begin_quote
- Simplifies integrity enforcement and data manipulation;
- Avoids data redundancy and the risk of database inconsistency;
- Guarantees semantic correctness: no update
  anomalies. [cite:@pascal_guide]
#+end_quote

PS: As an example of the impact to the bottom line, think of it means to
have to ~trust, but verify~ every piece of data you have. How many
checks, and in how many places? What if you forget one of those?

[[./287615-rose-window-strasbourg-cathedral-strasbourg-france.jpg]]

#+print_bibliography:

** How I do development on PostgreSQL over Emacs
:PROPERTIES:
:EXPORT_FILE_NAME: how-to-do-development-on-postgresql-over-emacs
:EXPORT_DATE: 2024-02-24
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug how-to-do-development-on-postgresql-over-emacs
:END:

These days I'm doing quite a lot of work in PostgreSql. Given that my
tool of choice is Emacs, I had to learn how to make do. This post's goal
is to document that.

First, I set up a connection

#+begin_src elisp
  (add-to-list 'sql-connection-alist
               `(production-read-only (sql-product 'postgres)
                                      (sql-user    "prod_user")
                                      (sql-server "data-aurora.cluster-ro.us-east-1.rds.amazonaws.com")
                                      (sql-database   "ProdDB")))
#+end_src

Since this uses psql under the covers and I want to not to have to type
passwords all the time, I store the passwords in ~~/.pgpass~.

#+begin_src shell
  # hostname:port:database:username:password
  data-aurora.cluster-ro.us-east-1.rds.amazonaws.com:5432:ProdDB:prod_user:the_password
#+end_src

In order to make life a bit better over at psql's prompt, I have a
~.psqlrc~ file with the following:

#+begin_src shell
  \set QUIET 1

  \set PROMPT1 '(%n@%m) [%/] > '
  \set PROMPT2 ''

  \pset null '[null]'
  \set COMP_KEYWORD_CASE upper
  \set HISTSIZE 2000
  \set VERBOSITY verbose
  \pset linestyle unicode
  \pset border 2
  \pset format wrapped

  \set QUIET 0
#+end_src

Finally, I'd like to keep the history of commands. Here is how I enable that on comint-mode:

#+begin_src elisp
  (use-package comint
    ;; This is based on
    ;; https://oleksandrmanzyuk.wordpress.com/2011/10/23/a-persistent-command-history-in-emacs/
    ;; The idea is to store sessions of comint based modes. For example, to enable
    ;; reading/writing of command history in, say, inferior-haskell-mode buffers,
    ;; simply add turn-on-comint-history to inferior-haskell-mode-hook by adding
    ;; it to the :hook directive
    :config
    (defun comint-write-history-on-exit (process event)
      (comint-write-input-ring)
      (let ((buf (process-buffer process)))
        (when (buffer-live-p buf)
          (with-current-buffer buf
            (insert (format "\nProcess %s %s" process event))))))

    (defun turn-on-comint-history ()
      (let ((process (get-buffer-process (current-buffer))))
        (when process
          (setq comint-input-ring-file-name
                (format "~/.emacs.d/inferior-%s-history"
                        (process-name process)))
          (comint-read-input-ring)
          (set-process-sentinel process
                                #'comint-write-history-on-exit))))

    (defun mapc-buffers (fn)
      (mapc (lambda (buffer)
              (with-current-buffer buffer
                (funcall fn)))
            (buffer-list)))

    (defun comint-write-input-ring-all-buffers ()
      (mapc-buffers 'comint-write-input-ring))

    (add-hook 'kill-emacs-hook 'comint-write-input-ring-all-buffers)
    (add-hook 'kill-buffer-hook 'comint-write-input-ring))

  (use-package sql
    :after comint
    :config
    (add-hook 'sql-interactive-mode-hook 'turn-on-comint-history)
    (setq sql-password-wallet (list "~/.authinfo.gpg")))
#+end_src

** Measurable behaviors of a leader
:PROPERTIES:
:EXPORT_FILE_NAME: performance-and-safety
:EXPORT_DATE: 2024-02-20
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug performance-and-safety
:END:

- building and maintaining a team
- providing direction through a vision
- creating realistic plans based on such vision
- getting the resources needed to execute the plan
- providing actionable feedback
- explaining how they make decisions

** Performance and safety
:PROPERTIES:
:EXPORT_FILE_NAME: performance-and-safety
:EXPORT_DATE: 2024-02-20
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug performance-and-safety
:END:

1. The human mind is limited in its capacity to understand complexity.
2. Concurrent software systems are among the most complex of all human creations.
3. Therefore, when you trade safety for performance, you will probably get neither.

** Renaming, not abstraction, is the problem of our industry
:PROPERTIES:
:EXPORT_FILE_NAME: renaming-not-abstraction
:EXPORT_DATE: 2024-01-30
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug renaming-not-abstraction
:END:

#+begin_quote
abstraction (n.) (Latin abs, from trahere, to draw).
#+end_quote

I've seen people I consider good software engineers complaining that
over-abstraction is a (the?) major problem in our industry today. Such
points are usually raised when discussing software architecture in
particular (one example: [cite:@arch_evolution]).

I'd like to defend abstraction, and how I don't think it is possible to
have over abstraction (in the same sense you cannot be overly good, or
overly healthy).

The definition I'd like to use for abstraction is this:

#+begin_quote
The most eminent Scholastics, however, following Aristotle, ascribe to
the mind in its higher aspect a power (called the Active Intellect)
which abstracts from the representations of concrete things or qualities
the typical, ideal, essential elements, leaving behind those that are
material and particular.  [cite:@deffy_abstraction]
#+end_quote

As one can see from such definition, the process is to select the
essentials from its concrete manifestation. On software engineering,
that means picking out the right form for your requirements, functional
or otherwise.

What I think people are complaining about is renaming/rebranding
concepts, which is rife in our industry (see the table on [[#cqrs-nominalism][CQRS as
nominalism]] for an example).

What to do then, as a software engineer? Go beyond names, and meditate
on the essences of your craft. What is a function, what is a relation,
what is a number? It will then not matter (to you at least) if someone
calls a function an object, or a relation a table.


#+print_bibliography:

** Measure, don’t guess.
:PROPERTIES:
:EXPORT_FILE_NAME: measure-dont-guess
:EXPORT_DATE: 2023-12-09
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug measure-dont-guess
:END:


#+begin_quote
... when you trade safety for performance, you may get
neither. Especially when it comes to concurrency, the intuition of many
developers about where a performance problem lies or which approach will
be faster or more scalable is often incorrect.

It is therefore imperative that any performance tuning exercise be
accompanied by concrete performance requirements (so you know both when
to tune and when to stop tuning) and with a measurement program in place
using a realistic configuration and load profile.


Measure again after tuning to verify that you’ve achieved the desired
improvements. The safety and maintenance risks associated with many
optimizations are bad enough—you don’t want to pay these costs if you
don’t need to—and you definitely don’t want to pay them if you don’t
even get the desired benefit. [cite:@goetz2006java]
#+end_quote



#+print_bibliography:

** A dangerous book
:PROPERTIES:
:EXPORT_FILE_NAME: dangerous-book
:EXPORT_DATE: 2024-01-04
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug dangerous-book
:END:


I recently [[https://www.linkedin.com/feed/update/urn:li:activity:7147881347099926528?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7147881347099926528%2C7148003385328271360%29&dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287148003385328271360%2Curn%3Ali%3Aactivity%3A7147881347099926528%29][commented]] on how the book [cite:@Kleppmann_Martin2017-05-02]
is a dangerous book, due to a subtle error on how it defines data
models. I suppose it's my burden to further clarify this point, and for
that I'll use Hayek's critical methodological maxim:

#+begin_quote
We must first explain how an economy can possibly work right before we
can meaningfully ask what might go wrong
#+end_quote

*** What is a data model?

Here are 3 definitions, in increasing level of detail:

#+begin_quote
A data model is an abstract, self-contained, logical definition of the
objects, operators, and so forth, that together constitute the abstract
machine with which users interact. The objects allow us to model the
structure of data. The operators allow us to model its behavior.
[cite:@10.5555/861613]:
#+end_quote

#+begin_quote
1) a collection of data structure types (the building blocks of any
   database that conforms to the model);
2) a collection of operators or inferencing rules, which can be applied
   to any valid instances of the data types listed in (i), to retrieve
   or derive data from any parts of those structures in any combinations
   desired;
3) a collection of general integrity rules, which implicitly or
   explicitly define the set of consistent database states or changes of
   state or both -- these rules may sometimes be expressed as
   insert-update-delete rules.

[cite:@10.1145/960124.806891]
#+end_quote

In particular, the Relational Data Model

#+begin_quote
1) An open-ended collection of scalar types, including type BOOLEAN in
   particular
2) A type generator and an intended interpretation for relations of
   types generated thereby
3) Facilities for defining variables of such generated
   relation types
4) A assignment operator for assigning values to such variables
5) A complete (but otherwise open-ended) collection of generic operators
   for deriving values from other values
[cite:@Date_Chris2015-12-15]
#+end_quote


Unfortunately, in our industry, it almost exclusively means a model of
which information is relevant to particular business cases. Those used
to be called Conceptual Schemas. It is part of the classic data model
progression[cite:@Steel1975b]:

Conceptual schema -> Logical schema -> Physical schema [fn:4]

What are those? I can't do better than [cite:@pascal_guide]

#+begin_quote
Think of a conceptual model as the territory, the logical model as its
symbolic representation on the map and the map print and medium (paper,
plastic, screen) as the physical model.
#+end_quote

How about the Data Model, how does it fit in this metaphor?

#+begin_quote
The data model is the map legend that provides the mapping symbols and
their correspondence to the elements of the territory (e.g., cities,
highways, forests and so on) they symbolize on the map.
#+end_quote

*** What is wrong with the book's definition?


[cite:@Kleppmann_Martin2017-05-02] does not provide an explicit
definition. The closest he has is this paragraph:

#+begin_quote
Most applications are built by layering one data model on top of
another. For each layer, the key question is: how is it represented in
terms of the next-lower layer?
#+end_quote

My translation of this, given the rest of the book's chapter on Data
Models, is that a Data Model for the author is any particular
implementation of a higher abstraction in a lower abstraction would
count as a Data Model. So, the author refers to all 4 models (and any
concrete instance of them) using the same term.

*** Why does this matter?

I hope that the consequences of such confusion would be clear to the
reader. If not, consider the advice of [cite:@pascal_guide]

#+begin_quote
Referring to all four as data models, or using the terms interchangeably
blurs the important differences, reflecting common confusion of levels
of representation, namely

- Conceptual-logical conflation (CLC);
- Logical-physical confusion (LPC).

with costly consequences.
#+end_quote

A single example from the book should suffice, I think:

#+begin_quote
There are several driving forces behind the adoption of NoSQL databases,
including:

- A need for greater scalability than relational databases can easily
  achieve, including very large datasets or very high write throughput
  ...
#+end_quote

Here, the author is confusing a Data Model (the relational data model)
with physical concerns (scalability and throughput), which might lead to
wrong (and very costly) technology and business decisions.

#+print_bibliography:
** Themes of the Elite Private School Curriculum
:PROPERTIES:
:EXPORT_FILE_NAME: theme-elite-schooling
:EXPORT_DATE: 2023-11-26
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug theme-elite-schooling
:END:

I think its fair to say that one can significantly improve one's chances
of being materially successful in life by learning John Taylor Gatto’s
14 Themes of the Elite Private School Curriculum[fn:5]:

1. A theory of human nature (as embodied in history, philosophy, theology,
   literature and law).

2. Skill in the active literacies (writing, public speaking).

3. Insight into the major institutional forms (courts, corporations, military,
   education).

4. Repeated exercises in the forms of good manners and politeness; based on
   the notion that they are the foundation of all future relationships, all
   future alliances, and access to places that you might want to go.

5. Independent work.

6. Energetic physical sports are the only way to confer grace on the human
   presence, and that that grace translates into power and money later on. Also,
   they teach you practice in handling pain, and in dealing with emergencies.

7. A complete theory of access to any place and any person.

8. Responsibility as an utterly essential part of the curriculum; always to
   grab it when it is offered and always to deliver more than is asked for.

9. Arrival at a personal code of standards (in production, behavior and
   morality).

10. To have a familiarity with, and to be at ease with, the fine
    arts. (cultural capital)

11. The power of accurate observation and recording. For example, sharpen the
    perception by being able to draw accurately.

12. The ability to deal with challenges of all sorts.

13. A habit of caution in reasoning to conclusions.

14. The constant development and testing of prior judgements: you make
    judgements, you discriminate value, and then you follow up and “keep an eye”
    on your predictions to see how far skewed, or how consistent, your
    predictions were.




** CQRS as nominalism
:PROPERTIES:
:EXPORT_FILE_NAME: cqrs-nominalism
:EXPORT_DATE: 2023-11-04
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug cqrs-nominalism
:CUSTOM_ID: cqrs-nominalism
:END:

A theme that I think is important to understand a lot of modernity and
the IT sector in particular, is nominalism.[fn:6]

So, what is Nominalism, and why does it matter? I'll start with a
concrete case and work my way to the abstract definition. The case in
point is a somewhat popular architecture tactic, CQRS.

What is CQRS? Here is an authoritative word on it[cite:@cqrs_young]:

#+begin_quote
Command and Query Responsibility Segregation (CQRS) originated with
Bertrand Meyer’s Command and Query Separation Principle

...

It states that every method should either be a command that performs an
action, or a query that returns data to the caller, but not both. In
other words, asking a question should not change the answer. More
formally, methods should return a value only if they are referentially
transparent and hence possess no side effects.

...

Basically it boils down to. If you have a return value you cannot mutate
state. If you mutate state your return type must be void.

...

in CQRS objects are split into two objects, one containing the Commands
one containing the Queries.
#+end_quote

CQRS is basically then an extension on CQS, but played on objects
instead of methods. It leverages the notions of immutable and mutable
objects, a feature it shares with a more encompassing approach,
DDD[cite:@Evans_Eric2014-09-22_ddd_ref]. Here is a mapping of the
terminology. [fn:7]

#+caption: CQRS/DDD/Traditional computer science terms mapping
| CQRS         | DDD                       | Traditional         | Interpretation                                                                                       |
|--------------+---------------------------+---------------------+------------------------------------------------------------------------------------------------------|
| Domain model | Entity                    | Variable            | A symbol that represents a value of a given type. Can represent  different values on different calls |
| Read model   | Value Object              | Value               | An element of a set                                                                                  |
| Command      | Aggregate command         | assignment operator | Change the value of a variable                                                                       |
| Query        | Side effect free function | function call       | Derive values from values                                                                            |


As this table shows, we have new names for old things, and people think
that because of that they *are* different things. My point is that this
is because of a nominalist position of the people on the CQRS community,
even if they are unaware of that. Why? Here's what nominalism is:

#+begin_quote
Nominalism ... denies the existence of abstract and universal concepts,
and refuses to admit that the intellect has the power of engendering
them. What are called general ideas are only names, mere verbal
designations, serving as labels for a collection of things or a series
of particular events. [cite:@wulf_universals]
#+end_quote

When you don't believe that general ideas exist as such, you have a
strong (inevitable?) tendency to mistake names for things, like the
CQRS community did here.

/PS/: Any implementation patterns that apply to CQRS would also apply to
the tradional concepts, since my point here is to show that *they are
the same thing*.

#+print_bibliography:

** On belts and value
:PROPERTIES:
:EXPORT_FILE_NAME: stand-out-short
:EXPORT_DATE: 2023-09-18
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug stand-out-short
:END:

Someone asked me about this, so I feel it might help people out there.

The short, no nonsense advise I give to people on standing out as a
programmer:

1. Generate results
2. Make your boss look good
3. Join a relevant open source project



** How to stand out in your career, the shortest version I know
:PROPERTIES:
:EXPORT_FILE_NAME: stand-out-short
:EXPORT_DATE: 2023-09-18
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug stand-out-short
:END:

Someone asked me about this, so I feel it might help people out there.

The short, no nonsense advise I give to people on standing out as a
programmer:

1. Generate results
2. Make your boss look good
3. Join a relevant open source project

** Recruitment and Selection of high performing programmers
:PROPERTIES:
:EXPORT_FILE_NAME: rec-sel-programmers
:EXPORT_DATE: 2023-08-26
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug rec-sel-programmers
:END:

What could be more important for a technology company than great
software? High performing software developers and their teams. After
all, they are the ones who actually create and maintain that great
software.

*** But do they really make a difference?

I'll let the numbers speak for themselves. Here are the typical
variations in:[cite:@diagram_variation_performance]

- Individual performance :: 20 to 1,

- Team performance :: 10 to 1,

- Method performance :: 1.2 to 1.


One can find a compelling illustration of these data on
[cite:@wilson-making-soft]. Two organizations, similar resources,
similar goal, vastly different performance:

- Microsoft excel 3 :: 649000 Lines of Code (Loc) in 50 Man Years (MY) = /12980/
- Lotus 123 :: 400000 LoC in 260 MY = /1538/

*** Recruitment and selection

#+begin_quote
Recruitment is the process of finding potential candidates to apply for
a job position, whereas selection is the process of identifying the best
candidate to hire. [cite:@rec_indeed]
#+end_quote

To find high performing candidates, you need to find markers of
belonging to some high performing culture. Usually something that is
very hard to master and that the marketplace ignores is a good bet. As
an exapmle, for backend developers, one might look for:

- Haskell or other functional programming language not in widespread
  use;

- Relational theory and other rigorous discipline misunderstood by the
  majority of the marketplace,

To filter them, I'd advise using a combination of the following methods
[cite:@schmidt_validity]:

  #+caption: Validity of selection methods
  | Procedure                           | Validity(r) | Multiple(R) | % gain |
  |-------------------------------------+-------------+-------------+--------|
  | GMA tests                           |         .65 |             |        |
  | Integrity tests                     |         .46 |         .78 |    20% |
  | Employment interviews (structured)  |         .58 |         .76 |    18% |
  | Employment interviews               |         .58 |         .73 |    13% |
  | Interests                           |         .31 |         .71 |    10% |
  | Phone-based interviews (structured) |         .46 |         .70 |     9% |
  | Conscientiousness                   |         .22 |         .70 |     8% |
  | Reference checks                    |         .26 |         .70 |     8% |
  | Openness to Experience              |         .04 |         .69 |     6% |
  | Biographical data                   |         .35 |         .68 |     6% |
  | Job experience (years)              |         .16 |         .68 |     5% |

For instance, a (GMA + Integrity + Conscientiousness + Structured
interview + Work Sample) combo should take at most 3 hours from the
candidate and 1 from your team.



#+print_bibliography:


** What is a good manager?   :management:
:PROPERTIES:
:EXPORT_FILE_NAME: what-is-a-good-manager
:EXPORT_DATE: 2023-07-29
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug what-is-a-good-manager
:END:


It is hard to do science without proper definitions. So what is a manager?

Abstracting from [cite:@horstman2016effective], my definition of a
manager is the following:

#+begin_quote
A manager continuously balances present output with creating the
conditions of future output.
#+end_quote


#+caption: The Good Sheperd, emblem found in a Roman catacomb, sec III
[[./good-shepherd.png]]

As one can see, this definition is similar to an investor. That is
expected, since a manager is an investor of a company's
resources. [fn:2]

As an illustration, a manager can usually deliver more results in the
present by burning up people. This probably will increase turnover in
the future. Is it the right choice? Only with a holistic view and sound
judgement can one decide correctly.

Given this definition, one can easily see that a good manager is *not*
some things:

- An extrovert
- A good communicator
- A frequent yeller
- Someone who cares
- Someone who is agreeable

#+print_bibliography:

** Is chatGPT replacing you? or: The nature of the intellectual act :philosophy:
:PROPERTIES:
:EXPORT_FILE_NAME: ai-intellectual-act
:EXPORT_DATE: 2023-07-11
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug ai-intellectual-act
:END:

I have come across people claiming to fear being replaced by bots,
specially chatGPT and other ~large language models (LLM)~. In this
article I'll take such statements at face value, despite my reservations
about the sincerity of many of them.

The short answer is to the question in the title is no, you will not get
replaced. The longer answer is below.

#+attr_shortcode: :side left
#+caption: Rudolph, Conrad. The Mystic Ark: Hugh of Saint Victor, Art, and Thought in the Twelfth Century.
[[./mystic-ark-hires-1.jpg]]

In order to understand if a LLM ~can~ replace you, you need to
understand what it is, since /agere sequitur esse/ (action follows
being). Here's what an authoritative source has to say about it:

#+begin_quote
The basic concept of ChatGPT is at some level rather simple. Start from
a huge sample of human-created text from the web, books, etc. Then train
a neural net to generate text that’s “like this”. And in particular,
make it able to start from a “prompt” and then continue with text that’s
“like what it’s been trained with”.

As we’ve seen, the actual neural net in ChatGPT is made up of very
simple elements—though billions of them. And the basic operation of the
neural net is also very simple, consisting essentially of passing input
derived from the text it’s generated so far “once through its elements”
(without any loops, etc.) for every new word (or part of a word) that it
generates. [cite:@chat_gpt_wolfram_2023]
#+end_quote

What it ~does~ is basically statistical correlation. So, what the
intellectual act of a person consists of? My summary of
[cite:@don_educ_fil]:

The intellectual act is a spiritual act, in contrast to a material
one. It consists in abstracting the essential form from individual
sensible perception. Grasping the universals out of particulars.

The last point is what I think underlies the actual fear. We live in a
nominalist age, such that[cite:@wulf_universals] it

#+begin_quote
... denies the existence of abstract and universal concepts, and refuses to
admit that the intellect has the power of engendering them.
#+end_quote

Therein lies the confusion that generates the fear. The correct
interpretation of reality is what has been traditionally called Moderate
Realism[cite:@wulf_universals]:

#+begin_quote
Moderate Realism, finally, declares that there are universal concepts
representing faithfully realities that are not universal.

How can there be harmony between the former and the latter? The latter
are particular, but we have the power of representing them to ourselves
abstractly. Now the abstract type, when the intellect considers it
reflectively and contrasts it with the particular subjects in which it
is realized or capable of being realized, is attributable indifferently
to any and all of them. This applicability of the abstract type to the
individuals is its universality.
#+end_quote

Fear not them, and trust in what you are analogous to, which is the
Intellect itself

#+print_bibliography:

** An illustrated way to enable openVPN on Qubes OS 4.1.2         :security:
:PROPERTIES:
:EXPORT_FILE_NAME: vpn-qubes
:EXPORT_DATE: 2023-07-01
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :slug vpn-qubes
:END:
#+begin_description
description of first post
#+end_description

In my view, Qubes OS lives up to its motto: ~A reasonably secure
operating system~. I use it for work and personal matters every day.

One challenging bit, when you use it in a work setting specially, is to
set up a VPN qube for your [[https://www.qubes-os.org/doc/glossary/#app-qube][app qubes]].

There are probably other ways to do this, but the way I chose to
structure my setup was the following:

#+caption: VPN network structure on Qubes
#+begin_src plantuml :file vpn_qubes.png :exports results :cache yes
  @startuml

  agent "sys-net" as sys_net      #Red
  agent "sys-firewall" as sys_firewall #Green
  agent "personal" as personal     #Yellow
  agent "work-vpn" as work_vpn     #Green
  agent "work" as work         #Blue

  personal     -up-> sys_firewall
  work         -up-> work_vpn
  work_vpn     -up-> sys_firewall
  sys_firewall -up-> sys_net

  @enduml
#+end_src

#+attr_shortcode: :src vpn_qubes.png :side left
#+RESULTS[92b96011d1891496217bb07761ac26457b642d99]:
[[file:vpn_qubes.png]]

After you create your [[https://www.qubes-os.org/doc/glossary/#app-qube][app qube]] for the VPN and assuming your template is
Debian, go to the template terminal (Debian 11) and run:

#+begin_src shell
  $ sudo apt install openvpn network-manager-openvpn-gnome
#+end_src

After this you should enable the network-manager service:

[[./vpn-network-service.png]]

Here comes the (for me) obscure trick: after importing your opvn file
through the network manager:

1. Go to IPv4 Settings tab
2. Click to the ~Routes...~ button
3. Select the ~Use this connection only for resources on its network~


Why does it work? I don't know. If you do, please email me.

** Index
:PROPERTIES:
:EXPORT_TITLE: blog section title
:EXPORT_FILE_NAME: _index
:END:
#+begin_description
this is the description of the blog section
#+end_description

* Footnotes
[fn:9] Including a claim of cost reductions of over 90%!

[fn:1] I like the terms superordinate, coordinates and subordinates, but
they are not in common usage

[fn:2] https://trends.google.com/trends/explore?date=all&geo=US&q=microservices

[fn:3] In a certain sense, all externally facing APIs face this. Microservices just make this problem worse by making everything ~external~ and not part of the same checkable runtime.

[fn:4] (schemas are synonymous to models in this context)

[fn:5] As listed in [[https://www.youtube.com/watch?v=IZBdv2yznmI][The Ultimate History Lesson]]

[fn:6] You will probably see me return to this topic in other posts.

[fn:7] I got the idea of such table from a similar table found on
chapter 25 of  [cite:@10.5555/861613]

[fn:8] The definitions come from [cite:@fallacies_iep], but the examples
are adapted to this context
